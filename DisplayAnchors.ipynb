{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"A7yb5zC1iHjj\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# Displaying Rotated Anchor Boxes\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"MzNkG8IziHjm\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow import keras\\n\",\n",
    "    \"\\n\",\n",
    "    \"import matplotlib.pyplot as plt\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class AnchorBox:\\n\",\n",
    "    \"    \\\"\\\"\\\"Generates anchor boxes.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    This class has operations to generate anchor boxes for feature maps at\\n\",\n",
    "    \"    strides `[8, 16, 32, 64, 128]`. Where each anchor each box is of the\\n\",\n",
    "    \"    format `[x, y, width, height, phi]`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Attributes:\\n\",\n",
    "    \"      aspect_ratios: A list of float values representing the aspect ratios of\\n\",\n",
    "    \"        the anchor boxes at each location on the feature map\\n\",\n",
    "    \"      scales: A list of float values representing the scale of the anchor boxes\\n\",\n",
    "    \"        at each location on the feature map.\\n\",\n",
    "    \"      num_anchors: The number of anchor boxes at each location on feature map\\n\",\n",
    "    \"      areas: A list of float values representing the areas of the anchor\\n\",\n",
    "    \"        boxes for each feature map in the feature pyramid.\\n\",\n",
    "    \"      strides: A list of float value representing the strides for each feature\\n\",\n",
    "    \"        map in the feature pyramid.\\n\",\n",
    "    \"      angles: A list of int values representing angles.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        self.aspect_ratios = [0.5, 1.0, 2.0]\\n\",\n",
    "    \"        #self.aspect_ratios = [1.0]\\n\",\n",
    "    \"        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\\n\",\n",
    "    \"        #self.scales = [2 ** x for x in [0, 1 / 3]]\\n\",\n",
    "    \"\\n\",\n",
    "    \"        #adding in angle data\\n\",\n",
    "    \"        self.angles = [0, -45,]\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\\n\",\n",
    "    \"        self._strides = [2 ** i for i in range(3, 8)]\\n\",\n",
    "    \"        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\\n\",\n",
    "    \"        self._anchor_dims = self._compute_dims()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _compute_dims(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Computes anchor box dimensions for all ratios and scales at all levels\\n\",\n",
    "    \"        of the feature pyramid.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        anchor_dims_all = []\\n\",\n",
    "    \"        for area in self._areas:\\n\",\n",
    "    \"            anchor_dims = []\\n\",\n",
    "    \"            for ratio in self.aspect_ratios:\\n\",\n",
    "    \"                anchor_height = tf.math.sqrt(area / ratio)\\n\",\n",
    "    \"                anchor_width = area / anchor_height\\n\",\n",
    "    \"                dims = tf.reshape(\\n\",\n",
    "    \"                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\\n\",\n",
    "    \"                )\\n\",\n",
    "    \"                for scale in self.scales:\\n\",\n",
    "    \"                    anchor_dims.append(scale * dims)\\n\",\n",
    "    \"            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\\n\",\n",
    "    \"        return anchor_dims_all\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _get_anchors(self, feature_height, feature_width, level, theta):\\n\",\n",
    "    \"        \\\"\\\"\\\"Generates anchor boxes for a given feature map size and level\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Arguments:\\n\",\n",
    "    \"          feature_height: An integer representing the height of the feature map.\\n\",\n",
    "    \"          feature_width: An integer representing the width of the feature map.\\n\",\n",
    "    \"          level: An integer representing the level of the feature map in the\\n\",\n",
    "    \"            feature pyramid.\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            \\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"          anchor boxes with the shape\\n\",\n",
    "    \"          `(feature_height * feature_width * num_anchors, 4)`\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        rx = tf.range(feature_width, dtype=tf.float32) + 0.5\\n\",\n",
    "    \"        ry = tf.range(feature_height, dtype=tf.float32) + 0.5\\n\",\n",
    "    \"        centers = tf.stack(tf.meshgrid(rx, ry), axis=-1) * self._strides[level - 3]\\n\",\n",
    "    \"        centers = tf.expand_dims(centers, axis=-2)\\n\",\n",
    "    \"        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\\n\",\n",
    "    \"        dims = tf.tile(\\n\",\n",
    "    \"            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        anchors = tf.concat([centers, dims], axis=-1)\\n\",\n",
    "    \"        reshaped = tf.reshape(\\n\",\n",
    "    \"            anchors, [feature_height * feature_width * self._num_anchors, 4]\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        test = reshaped.numpy()\\n\",\n",
    "    \"        return reshaped\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def get_anchors(self, image_height, image_width):\\n\",\n",
    "    \"        \\\"\\\"\\\"Generates anchor boxes for all the feature maps of the feature pyramid.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Arguments:\\n\",\n",
    "    \"          image_height: Height of the input image.\\n\",\n",
    "    \"          image_width: Width of the input image.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"          anchor boxes for all the feature maps, stacked as a single tensor\\n\",\n",
    "    \"            with shape `(total_anchors, 4)`\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        anchors = [\\n\",\n",
    "    \"            self._get_anchors(\\n\",\n",
    "    \"                tf.math.ceil(image_height / 2 ** i),\\n\",\n",
    "    \"                tf.math.ceil(image_width / 2 ** i),\\n\",\n",
    "    \"                i,\\n\",\n",
    "    \"                self.angles,\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            for i in range(3, 8)\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"        return tf.concat(anchors, axis=0)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def visualize_detections(\\n\",\n",
    "    \"    image, boxes, figsize=(7, 7), linewidth=1, color=[0, 0, 1]\\n\",\n",
    "    \"):\\n\",\n",
    "    \"    \\\"\\\"\\\"Visualize Detections\\\"\\\"\\\"\\n\",\n",
    "    \"    image = np.array(image, dtype=np.uint8)\\n\",\n",
    "    \"    plt.figure(figsize=figsize)\\n\",\n",
    "    \"    plt.axis(\\\"off\\\")\\n\",\n",
    "    \"    plt.imshow(image)\\n\",\n",
    "    \"    ax = plt.gca()\\n\",\n",
    "    \"    for box in boxes:\\n\",\n",
    "    \"        x1, y1, x2, y2 = box\\n\",\n",
    "    \"        w, h = x2 - x1, y2 - y1\\n\",\n",
    "    \"        patch = plt.Rectangle(\\n\",\n",
    "    \"            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        ax.add_patch(patch)\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    return ax\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"2022-04-24 20:43:19.483322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.483636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.490227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.490510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.490836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.491039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.491930: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\\n\",\n",
    "      \"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n\",\n",
    "      \"2022-04-24 20:43:19.670036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.670267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.670462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.670642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.670821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:19.671001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:20.352310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:20.352590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:20.352788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:20.352979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:20.353170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:20.353352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 35 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:0d:00.0, compute capability: 6.1\\n\",\n",
    "      \"2022-04-24 20:43:20.353838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-04-24 20:43:20.353989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5196 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:0c:00.0, compute capability: 6.1\\n\",\n",
    "      \"2022-04-24 20:43:20.358455: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 35.12M (36831232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\\n\",\n",
    "      \"2022-04-24 20:43:20.359295: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 31.61M (33148160 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"boxes = AnchorBox()\\n\",\n",
    "    \"img = tf.zeros([100, 100, 3])\\n\",\n",
    "    \"\\n\",\n",
    "    \"anchors = boxes.get_anchors(100, 100)\\n\",\n",
    "    \"\\n\",\n",
    "    \"anchor_dims = boxes._compute_dims()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"image/png\": \"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\\n\",\n",
    "      \"text/plain\": [\n",
    "       \"<Figure size 504x504 with 1 Axes>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {\n",
    "      \"needs_background\": \"light\"\n",
    "     },\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<AxesSubplot:>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 5,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"visualize_detections(img, anchors)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"colab\": {\n",
    "   \"collapsed_sections\": [],\n",
    "   \"name\": \"retinanet\",\n",
    "   \"provenance\": [],\n",
    "   \"toc_visible\": true\n",
    "  },\n",
    "  \"interpreter\": {\n",
    "   \"hash\": \"61c63460f299b72050a017299847de40e48391aa12573d6685850838867f4476\"\n",
    "  },\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"RLModel\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"rlmodel\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
