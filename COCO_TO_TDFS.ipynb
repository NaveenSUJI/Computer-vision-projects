{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import collections\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"from absl import logging\\n\",\n",
    "    \"import tensorflow.compat.v2 as tf\\n\",\n",
    "    \"\\n\",\n",
    "    \"import tensorflow_datasets.public_api as tfds\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\\"\\\"\\\"mvtec_screws COCO STYLE DATASET.\\\"\\\"\\\"\\n\",\n",
    "    \"_CITATION = \\\"\\\"\\\"\\\\\\n\",\n",
    "    \"@article{NA,\\n\",\n",
    "    \"  author    = {NA},\\n\",\n",
    "    \"  title     = {MVTEC SCREWS DATASET},\\n\",\n",
    "    \"  journal   = {NA},\\n\",\n",
    "    \"  volume    = {NA},\\n\",\n",
    "    \"  year      = {NA},\\n\",\n",
    "    \"  url       = {NA},\\n\",\n",
    "    \"  archivePrefix = {NA},\\n\",\n",
    "    \"  eprint    = {NA},\\n\",\n",
    "    \"  timestamp = {NA},\\n\",\n",
    "    \"  biburl    = {NA},\\n\",\n",
    "    \"  bibsource = {NA},\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"_DESCRIPTION = \\\"\\\"\\\"\\n\",\n",
    "    \"Note:\\n\",\n",
    "    \" * \\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"_CONFIG_DESCRIPTION = \\\"\\\"\\\"\\n\",\n",
    "    \"This version contains images, bounding boxes, orientation and labels.\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"Split = collections.namedtuple(\\n\",\n",
    "    \"    'Split', ['name', 'images', 'annotations', 'annotation_type'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class AnnotationType(object):\\n\",\n",
    "    \"  \\\"\\\"\\\"Enum of the annotation format types.\\n\",\n",
    "    \"\\n\",\n",
    "    \"  Splits are annotated with different formats.\\n\",\n",
    "    \"  \\\"\\\"\\\"\\n\",\n",
    "    \"  BBOXES = 'bboxes'\\n\",\n",
    "    \"  NONE = 'none'\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class MVTEC_SCREWSConfig(tfds.core.BuilderConfig):\\n\",\n",
    "    \"  \\\"\\\"\\\"BuilderConfig for mvtec_screwsConfig.\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def __init__(self, splits=None, **kwargs):\\n\",\n",
    "    \"    super(MVTEC_SCREWSConfig, self).__init__(\\n\",\n",
    "    \"        version=tfds.core.Version('1.1.0'), **kwargs)\\n\",\n",
    "    \"    self.splits = splits\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class MVTEC_SCREWS(tfds.core.GeneratorBasedBuilder):\\n\",\n",
    "    \"  \\\"\\\"\\\"Base Screws dataset.\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"  MANUAL_DOWNLOAD_INSTRUCTIONS = \\\"\\\"\\\"\\n\",\n",
    "    \"  Register into https://example.org/login to get the data. Place the `data.zip`\\n\",\n",
    "    \"  file in the `manual_dir/`.\\n\",\n",
    "    \"  \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"  BUILDER_CONFIGS = [\\n\",\n",
    "    \"      MVTEC_SCREWSConfig(\\n\",\n",
    "    \"          name='mvtec_screws',\\n\",\n",
    "    \"          description=_CONFIG_DESCRIPTION.format(year=2022),\\n\",\n",
    "    \"          splits=[\\n\",\n",
    "    \"              Split(\\n\",\n",
    "    \"                  name=tfds.Split.TRAIN,\\n\",\n",
    "    \"                  images='train',\\n\",\n",
    "    \"                  annotations='annotations_trainval',\\n\",\n",
    "    \"                  annotation_type=AnnotationType.BBOXES,\\n\",\n",
    "    \"              ),\\n\",\n",
    "    \"          ],\\n\",\n",
    "    \"      ),\\n\",\n",
    "    \"  ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def _info(self):\\n\",\n",
    "    \"    features = {\\n\",\n",
    "    \"        # Images can have variable shape\\n\",\n",
    "    \"        'image': tfds.features.Image(),\\n\",\n",
    "    \"        'image/filename': tfds.features.Text(),\\n\",\n",
    "    \"        'image/id': tf.int64,\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    # Uses original annotations\\n\",\n",
    "    \"    if True:\\n\",\n",
    "    \"      features.update({\\n\",\n",
    "    \"          'objects':\\n\",\n",
    "    \"              tfds.features.Sequence({\\n\",\n",
    "    \"                  'id': tf.int64,\\n\",\n",
    "    \"                  # Coco has unique id for each annotation. The id can be used\\n\",\n",
    "    \"                  # for mapping panoptic image to semantic segmentation label.\\n\",\n",
    "    \"                  'area': tf.int64,\\n\",\n",
    "    \"                  'bbox': tfds.features.BBoxFeature(),\\n\",\n",
    "    \"                  'phi': tf.float32,\\n\",\n",
    "    \"                  'label': tfds.features.ClassLabel(num_classes=13),\\n\",\n",
    "    \"                  'is_crowd': tf.bool,\\n\",\n",
    "    \"              }),\\n\",\n",
    "    \"      })\\n\",\n",
    "    \"    # More info could be added, like segmentation (as png mask), captions,\\n\",\n",
    "    \"    # person key-points, more metadata (original flickr url,...).\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return tfds.core.DatasetInfo(\\n\",\n",
    "    \"        builder=self,\\n\",\n",
    "    \"        description=_DESCRIPTION,\\n\",\n",
    "    \"        # More info could be added, like the segmentation (as png mask),\\n\",\n",
    "    \"        # captions, person key-points. For caption encoding, it would probably\\n\",\n",
    "    \"        # be better to have a separate class CocoCaption2014 to avoid poluting\\n\",\n",
    "    \"        # the main class with builder config for each encoder.\\n\",\n",
    "    \"        features=tfds.features.FeaturesDict(features),\\n\",\n",
    "    \"        homepage='NA',\\n\",\n",
    "    \"        citation=_CITATION,\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def _split_generators(self, dl_manager):\\n\",\n",
    "    \"    # data_path is a pathlib-like `Path('<manual_dir>/data.zip')`\\n\",\n",
    "    \"    archive_path = dl_manager.manual_dir / 'mvtec_screws_data.zip'\\n\",\n",
    "    \"    print(dl_manager.manual_dir)\\n\",\n",
    "    \"    # Extract the manually downloaded `data.zip`\\n\",\n",
    "    \"    extracted_path = dl_manager.extract(archive_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    extracted_paths = dict()\\n\",\n",
    "    \"    with os.scandir(extracted_path) as file_list:\\n\",\n",
    "    \"        for f in file_list:\\n\",\n",
    "    \"            print(f.name)\\n\",\n",
    "    \"            extracted_paths[f.name] = f.path\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    splits = []\\n\",\n",
    "    \"    for split in self.builder_config.splits:\\n\",\n",
    "    \"      image_dir = extracted_paths['{}_images'.format(split.name)]\\n\",\n",
    "    \"      annotations_dir = extracted_paths['{}_annotations'.format(split.name)]\\n\",\n",
    "    \"\\n\",\n",
    "    \"      splits.append(\\n\",\n",
    "    \"          tfds.core.SplitGenerator(\\n\",\n",
    "    \"              name=split.name,\\n\",\n",
    "    \"              gen_kwargs=dict(\\n\",\n",
    "    \"                  image_dir=image_dir,\\n\",\n",
    "    \"                  annotation_dir=annotations_dir,\\n\",\n",
    "    \"                  split_name=split.images,\\n\",\n",
    "    \"                  annotation_type=split.annotation_type,\\n\",\n",
    "    \"              ),\\n\",\n",
    "    \"          ))\\n\",\n",
    "    \"    return splits\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def _generate_examples(self, image_dir, annotation_dir, split_name,\\n\",\n",
    "    \"                         annotation_type):\\n\",\n",
    "    \"    \\\"\\\"\\\"Generate examples as dicts.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"      image_dir: `str`, directory containing the images\\n\",\n",
    "    \"      annotation_dir: `str`, directory containing annotations\\n\",\n",
    "    \"      split_name: `str`, <split_name><year> (ex: train2014, val2017)\\n\",\n",
    "    \"      annotation_type: `AnnotationType`, the annotation format (NONE, BBOXES)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Yields:\\n\",\n",
    "    \"      example key and data\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if annotation_type == AnnotationType.BBOXES:\\n\",\n",
    "    \"      instance_filename = 'instances_{}.json'\\n\",\n",
    "    \"    elif annotation_type == AnnotationType.NONE:  # No annotation for test sets\\n\",\n",
    "    \"      instance_filename = 'image_info_{}.json'\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Load the annotations (label names, images metadata,...)\\n\",\n",
    "    \"    instance_path = os.path.join(\\n\",\n",
    "    \"        annotation_dir,\\n\",\n",
    "    \"        'annotations',\\n\",\n",
    "    \"        instance_filename.format(split_name),\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    coco_annotation = ANNOTATION_CLS[annotation_type](instance_path)\\n\",\n",
    "    \"    # Each category is a dict:\\n\",\n",
    "    \"    # {\\n\",\n",
    "    \"    #    'id': 51,  # From 1-91, some entry missing\\n\",\n",
    "    \"    #    'name': 'bowl',\\n\",\n",
    "    \"    #    'supercategory': 'kitchen',\\n\",\n",
    "    \"    # }\\n\",\n",
    "    \"    categories = coco_annotation.categories\\n\",\n",
    "    \"    # Each image is a dict:\\n\",\n",
    "    \"    # {\\n\",\n",
    "    \"    #     'id': 262145,\\n\",\n",
    "    \"    #     'file_name': 'COCO_train2017_000000262145.jpg'\\n\",\n",
    "    \"    #     'flickr_url': 'http://farm8.staticflickr.com/7187/xyz.jpg',\\n\",\n",
    "    \"    #     'coco_url': 'http://images.cocodataset.org/train2017/xyz.jpg',\\n\",\n",
    "    \"    #     'license': 2,\\n\",\n",
    "    \"    #     'date_captured': '2013-11-20 02:07:55',\\n\",\n",
    "    \"    #     'height': 427,\\n\",\n",
    "    \"    #     'width': 640,\\n\",\n",
    "    \"    # }\\n\",\n",
    "    \"    images = coco_annotation.images\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # TODO(b/121375022): ClassLabel names should also contains 'id' and\\n\",\n",
    "    \"    # and 'supercategory' (in addition to 'name')\\n\",\n",
    "    \"    # Warning: As Coco only use 80 out of the 91 labels, the c['id'] and\\n\",\n",
    "    \"    # dataset names ids won't match.\\n\",\n",
    "    \"    if True:\\n\",\n",
    "    \"      objects_key = 'objects'\\n\",\n",
    "    \"    self.info.features[objects_key]['label'].names = [\\n\",\n",
    "    \"        c['name'] for c in categories\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"    # TODO(b/121375022): Conversion should be done by ClassLabel\\n\",\n",
    "    \"    categories_id2name = {c['id']: c['name'] for c in categories}\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Iterate over all images\\n\",\n",
    "    \"    annotation_skipped = 0\\n\",\n",
    "    \"    for image_info in sorted(images, key=lambda x: x['id']):\\n\",\n",
    "    \"      if annotation_type == AnnotationType.BBOXES:\\n\",\n",
    "    \"        # Each instance annotation is a dict:\\n\",\n",
    "    \"        # {\\n\",\n",
    "    \"        #     'iscrowd': 0,\\n\",\n",
    "    \"        #     'bbox': [116.95, 305.86, 285.3, 266.03],\\n\",\n",
    "    \"        #     'image_id': 480023,\\n\",\n",
    "    \"        #     'segmentation': [[312.29, 562.89, 402.25, ...]],\\n\",\n",
    "    \"        #     'category_id': 58,\\n\",\n",
    "    \"        #     'area': 54652.9556,\\n\",\n",
    "    \"        #     'id': 86,\\n\",\n",
    "    \"        # }\\n\",\n",
    "    \"        instances = coco_annotation.get_annotations(img_id=image_info['id'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"      else:\\n\",\n",
    "    \"        instances = []  # No annotations\\n\",\n",
    "    \"\\n\",\n",
    "    \"      if not instances:\\n\",\n",
    "    \"        annotation_skipped += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"      def build_bbox(x, y, width, height):\\n\",\n",
    "    \"        # pylint: disable=cell-var-from-loop\\n\",\n",
    "    \"        # build_bbox is only used within the loop so it is ok to use image_info\\n\",\n",
    "    \"        return tfds.features.BBox(\\n\",\n",
    "    \"            ymin=(y - y*.5)/ image_info['height'],\\n\",\n",
    "    \"            xmin=(x - x*.5)/ image_info['width'],\\n\",\n",
    "    \"            ymax=((y - y*.5) + height) / image_info['height'],\\n\",\n",
    "    \"            xmax=((x - x*.5) + width) / image_info['width'],\\n\",\n",
    "    \"            #ymin=y,\\n\",\n",
    "    \"            #xmin=x,\\n\",\n",
    "    \"            #ymax=y+height,\\n\",\n",
    "    \"            #xmax=x+width,\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        # pylint: enable=cell-var-from-loop\\n\",\n",
    "    \"\\n\",\n",
    "    \"      example = {\\n\",\n",
    "    \"          'image': os.path.join(image_dir, split_name, image_info['file_name']),\\n\",\n",
    "    \"          'image/filename': image_info['file_name'],\\n\",\n",
    "    \"          'image/id': image_info['id'],\\n\",\n",
    "    \"          objects_key: [{   # pylint: disable=g-complex-comprehension\\n\",\n",
    "    \"              'id': instance['id'],\\n\",\n",
    "    \"              'area': instance['area'],\\n\",\n",
    "    \"              'bbox': build_bbox(instance['bbox'][0],instance['bbox'][1],instance['bbox'][2], instance['bbox'][3]),\\n\",\n",
    "    \"              'phi': instance['bbox'][4],\\n\",\n",
    "    \"              'label': categories_id2name[instance['category_id']],\\n\",\n",
    "    \"              'is_crowd': bool(instance['is_crowd']),\\n\",\n",
    "    \"          } for instance in instances]\\n\",\n",
    "    \"      }\\n\",\n",
    "    \"\\n\",\n",
    "    \"      yield image_info['file_name'], example\\n\",\n",
    "    \"\\n\",\n",
    "    \"    logging.info(\\n\",\n",
    "    \"        '%d/%d images do not contains any annotations',\\n\",\n",
    "    \"        annotation_skipped,\\n\",\n",
    "    \"        len(images),\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class CocoAnnotation(object):\\n\",\n",
    "    \"  \\\"\\\"\\\"Coco annotation helper class.\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def __init__(self, annotation_path):\\n\",\n",
    "    \"    with tf.io.gfile.GFile(annotation_path) as f:\\n\",\n",
    "    \"      data = json.load(f)\\n\",\n",
    "    \"    self._data = data\\n\",\n",
    "    \"\\n\",\n",
    "    \"  @property\\n\",\n",
    "    \"  def categories(self):\\n\",\n",
    "    \"    \\\"\\\"\\\"Return the category dicts, as sorted in the file.\\\"\\\"\\\"\\n\",\n",
    "    \"    return self._data['categories']\\n\",\n",
    "    \"\\n\",\n",
    "    \"  @property\\n\",\n",
    "    \"  def images(self):\\n\",\n",
    "    \"    \\\"\\\"\\\"Return the image dicts, as sorted in the file.\\\"\\\"\\\"\\n\",\n",
    "    \"    return self._data['images']\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def get_annotations(self, img_id):\\n\",\n",
    "    \"    \\\"\\\"\\\"Return all annotations associated with the image id string.\\\"\\\"\\\"\\n\",\n",
    "    \"    raise NotImplementedError  # AnotationType.NONE don't have annotations\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class CocoAnnotationBBoxes(CocoAnnotation):\\n\",\n",
    "    \"  \\\"\\\"\\\"Coco annotation helper class.\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def __init__(self, annotation_path):\\n\",\n",
    "    \"    super(CocoAnnotationBBoxes, self).__init__(annotation_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    img_id2annotations = collections.defaultdict(list)\\n\",\n",
    "    \"    for a in self._data['annotations']:\\n\",\n",
    "    \"      img_id2annotations[a['image_id']].append(a)\\n\",\n",
    "    \"    self._img_id2annotations = {\\n\",\n",
    "    \"        k: list(sorted(v, key=lambda a: a['id']))\\n\",\n",
    "    \"        for k, v in img_id2annotations.items()\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def get_annotations(self, img_id):\\n\",\n",
    "    \"    \\\"\\\"\\\"Return all annotations associated with the image id  string.\\\"\\\"\\\"\\n\",\n",
    "    \"    # Some images don't have any annotations. Return empty list instead.\\n\",\n",
    "    \"    return self._img_id2annotations.get(img_id, [])\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class CocoAnnotationPanoptic(CocoAnnotation):\\n\",\n",
    "    \"  \\\"\\\"\\\"Coco annotation helper class.\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def __init__(self, annotation_path):\\n\",\n",
    "    \"    super(CocoAnnotationPanoptic, self).__init__(annotation_path)\\n\",\n",
    "    \"    self._img_id2annotations = {\\n\",\n",
    "    \"        a['image_id']: a for a in self._data['annotations']\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def get_annotations(self, img_id):\\n\",\n",
    "    \"    \\\"\\\"\\\"Return all annotations associated with the image id string.\\\"\\\"\\\"\\n\",\n",
    "    \"    return self._img_id2annotations[img_id]\\n\",\n",
    "    \"\\n\",\n",
    "    \"ANNOTATION_CLS = {\\n\",\n",
    "    \"    AnnotationType.NONE: CocoAnnotation,\\n\",\n",
    "    \"    AnnotationType.BBOXES: CocoAnnotationBBoxes,\\n\",\n",
    "    \"}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/amarchia/repos/CV22Project\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"print(os.getcwd())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"2022-03-18 22:38:57.125442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.126122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.132890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.133569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.134249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.134792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.136227: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\\n\",\n",
    "      \"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n\",\n",
    "      \"2022-03-18 22:38:57.321711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.322541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.323214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.323952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.324612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:57.325312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:58.059259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:58.059823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:58.060322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:58.060904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:58.061395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:58.061975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7398 MB memory:  -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:0d:00.0, compute capability: 6.1\\n\",\n",
    "      \"2022-03-18 22:38:58.062460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n\",\n",
    "      \"2022-03-18 22:38:58.062910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5385 MB memory:  -> device: 1, name: GeForce GTX 1060 6GB, pci bus id: 0000:0c:00.0, compute capability: 6.1\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"if __name__ == \\\"__main__\\\":\\n\",\n",
    "    \"    ds = tfds.load(\\\"mvtec_screws\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"interpreter\": {\n",
    "   \"hash\": \"61c63460f299b72050a017299847de40e48391aa12573d6685850838867f4476\"\n",
    "  },\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"TensorFlow Testing\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"tf-testing\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
